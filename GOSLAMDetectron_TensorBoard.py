# -*- coding: utf-8 -*-
"""GOSLAMDetectronV1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K9qxTvsUw7RSyZn_qJauTMEcWLEjLN4S
"""

import sys, os, distutils.core
!git clone 'https://github.com/facebookresearch/detectron2'
dist = distutils.core.run_setup("./detectron2/setup.py")
!python -m pip install {' '.join([f"'{x}'" for x in dist.install_requires])}
sys.path.insert(0, os.path.abspath('./detectron2'))

# Install Detectron2 dependencies
!pip install pyyaml==5.1
# !pip install torch==1.10.0 torchvision==0.11.1 torchaudio==0.10.0
!pip install opencv-python-headless

# Install Detectron2
# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html

# Install other necessary libraries
!pip install tensorboard

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
FOLDERNAME = 'ColabNotebooks/cs231nfinalproject/datasets/'
assert FOLDERNAME is not None, "[!] Enter the foldername."


import sys
sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))

# %cd /content/drive/My\ Drive/$FOLDERNAME
# %ls /content/drive/My\ Drive/$FOLDERNAME

!cp /content/drive/My\ Drive/$FOLDERNAME/merged_dataset.zip /content/dataset.zip

# Unzip the dataset
!unzip /content/dataset.zip -d /content/dataset

!ls /content/dataset/merged_dataset

!ls /content/dataset/merged_dataset/annotations
# !ls /content/dataset/IndoorObjectsDetectionCOCO/train
# !ls /content/dataset/IndoorObjectsDetectionCOCO/val
# !ls /content/dataset/IndoorObjectsDetectionCOCO/test

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

# from detectron2.engine import DefaultTrainer, DefaultPredictor
# from detectron2.config import get_cfg
# from detectron2.utils.visualizer import Visualizer
# from detectron2.data import MetadataCatalog, DatasetCatalog
# from detectron2.data.datasets import register_coco_instances
# import os
# import matplotlib.pyplot as plt
# import cv2


# # Path to the dataset
# dataset_path = "/content/dataset/merged_dataset"
# annotations_path = os.path.join(dataset_path, "annotations")

# # Print paths to verify
# print("Dataset path:", dataset_path)
# print("Annotations path:", annotations_path)

# # Function to unregister dataset if already registered
# def unregister_dataset(name):
#     if name in MetadataCatalog:
#         del MetadataCatalog[name]
#     if name in DatasetCatalog:
#         del DatasetCatalog[name]

# # Function to register datasets
# def register_dataset(name, json_file, image_root):
#     unregister_dataset(name)  # Unregister the dataset if already registered
#     print(f"Registering dataset: {name}")
#     print(f"JSON file: {json_file}")
#     print(f"Image root: {image_root}")
#     register_coco_instances(name, {}, json_file, image_root)

# # Register the merged datasets
# for split in ["train", "val", "test"]:
#     unregister_dataset(f"custom_{split}")
#     # register_dataset(f"custom_{split}", f"custom_{split}.json", f"{split}")
#     register_dataset(f"custom_{split}", os.path.join(annotations_path, f"custom_{split}.json"), os.path.join(dataset_path, f"{split}"))


# # Configuration setup
# cfg = get_cfg()
# cfg.merge_from_file(detectron2.model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
# cfg.DATASETS.TRAIN = ("custom_train",)
# cfg.DATASETS.TEST = ("custom_val",)
# cfg.DATALOADER.NUM_WORKERS = 2
# cfg.MODEL.WEIGHTS = detectron2.model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")  # Pretrained weights
# cfg.SOLVER.IMS_PER_BATCH = 2
# cfg.SOLVER.BASE_LR = 0.00025  # Learning rate
# cfg.SOLVER.MAX_ITER = 1000  # Number of iterations
# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # Number of classes (change accordingly)
# cfg.OUTPUT_DIR = "./output"

# # Trainer setup
# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
# trainer = DefaultTrainer(cfg)
# trainer.resume_or_load(resume=False)
# trainer.train()

# # Evaluation setup
# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for this model
# cfg.DATASETS.TEST = ("custom_test",)
# predictor = DefaultPredictor(cfg)

# from detectron2.evaluation import COCOEvaluator, inference_on_dataset
# from detectron2.data import build_detection_test_loader

# evaluator = COCOEvaluator("custom_test", cfg, False, output_dir="./output/")
# val_loader = build_detection_test_loader(cfg, "custom_test")
# evaluation_results = inference_on_dataset(predictor.model, val_loader, evaluator)
# print(evaluation_results)

# # Plotting and saving predictions
# test_metadata = MetadataCatalog.get("custom_test")
# test_dataset_dicts = DatasetCatalog.get("custom_test")

# os.makedirs("./output/plots", exist_ok=True)  # Directory to save plotted images

# for idx, d in enumerate(test_dataset_dicts[:5]):  # Visualize first 5 test images
#     img = cv2.imread(d["file_name"])
#     outputs = predictor(img)
#     v = Visualizer(img[:, :, ::-1], metadata=test_metadata, scale=1.2)
#     out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

#     plt.figure(figsize=(10, 10))
#     plt.imshow(out.get_image()[:, :, ::-1])
#     plt.axis('off')
#     plt.title(d["file_name"])
#     plt.savefig(f"./output/plots/prediction_{idx}.png")
#     plt.show()

import detectron2
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.data.datasets import register_coco_instances
import os

# Path to the dataset
dataset_path = "/content/dataset/merged_dataset"
annotations_path = os.path.join(dataset_path, "annotations")

# Print paths to verify
print("Dataset path:", dataset_path)
print("Annotations path:", annotations_path)

# Function to unregister dataset if already registered
def unregister_dataset(name):
    if name in MetadataCatalog:
        del MetadataCatalog[name]
    if name in DatasetCatalog:
        del DatasetCatalog[name]

# Function to register datasets
def register_dataset(name, json_file, image_root):
    unregister_dataset(name)  # Unregister the dataset if already registered
    print(f"Registering dataset: {name}")
    print(f"JSON file: {json_file}")
    print(f"Image root: {image_root}")
    register_coco_instances(name, {}, json_file, image_root)


# Register datasets
unregister_dataset("custom_train")
unregister_dataset("custom_val")
unregister_dataset("custom_test")
register_dataset("custom_train", os.path.join(annotations_path, "custom_train.json"), os.path.join(dataset_path, "train"))
register_dataset("custom_val", os.path.join(annotations_path, "custom_val.json"), os.path.join(dataset_path, "val"))
register_dataset("custom_test", os.path.join(annotations_path, "custom_test.json"), os.path.join(dataset_path, "test"))

from detectron2.engine import DefaultTrainer, DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
import matplotlib.pyplot as plt
import cv2
import os
from detectron2.modeling import build_model

# Configuration setup
cfg = get_cfg()
cfg.merge_from_file(detectron2.model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("custom_train",)
cfg.DATASETS.TEST = ("custom_val",)
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = detectron2.model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")  # Pretrained weights
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # Number of classes (change accordingly)
cfg.OUTPUT_DIR = "./outputold"

# Configure your model and training parameters
cfg.SOLVER.IMS_PER_BATCH = 10
cfg.SOLVER.BASE_LR = 0.001
cfg.SOLVER.MAX_ITER = 1000

# Build the model
model = build_model(cfg)

# Freeze the layers
for name, parameter in model.named_parameters():
    if 'roi_heads' not in name:
        parameter.requires_grad = False

# Training setup
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

# Evaluation setup
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for this model
cfg.DATASETS.TEST = ("custom_test",)
predictor = DefaultPredictor(cfg)

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

evaluator = COCOEvaluator("custom_test", cfg, False, output_dir="./outputold/")
val_loader = build_detection_test_loader(cfg, "custom_test")
evaluation_results = inference_on_dataset(predictor.model, val_loader, evaluator)
print(evaluation_results)

# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
# %reload_ext tensorboard
# %tensorboard --logdir ./outputold/

# Plotting and saving predictions
test_metadata = MetadataCatalog.get("custom_test")
test_dataset_dicts = DatasetCatalog.get("custom_test")

os.makedirs("./outputold/plots", exist_ok=True)  # Directory to save plotted images

for idx, d in enumerate(test_dataset_dicts[:5]):  # Visualize first 5 test images
    img = cv2.imread(d["file_name"])
    outputs = predictor(img)
    v = Visualizer(img[:, :, ::-1], metadata=test_metadata, scale=0.8)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    plt.figure(figsize=(14, 10))
    plt.imshow(out.get_image()[:, :, ::-1])
    plt.axis('off')

    plot_path = f"./outputold/plots/prediction_{idx}.png"
    plt.savefig(plot_path)  # Save the plot
    plt.show()

import os
import random
import cv2
import matplotlib.pyplot as plt
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.utils.visualizer import Visualizer

test_metadata = MetadataCatalog.get("custom_test")
test_dataset_dicts = DatasetCatalog.get("custom_test")

os.makedirs("./outputold/plots", exist_ok=True)  # Directory to save plotted images

# Select 10 random entries from the test dataset
random_entries = random.sample(test_dataset_dicts, 10)

for idx, d in enumerate(random_entries):  # Visualize 10 random test images
    img = cv2.imread(d["file_name"])
    outputs = predictor(img)
    v = Visualizer(img[:, :, ::-1], metadata=test_metadata, scale=0.8)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    plt.figure(figsize=(14, 10))
    plt.imshow(out.get_image()[:, :, ::-1])
    plt.axis('off')

    plot_path = f"./outputold/plots/prediction_{idx}.png"
    plt.savefig(plot_path)  # Save the plot
    plt.show()

# Step 3: Upload images
from google.colab import files
import os

# Upload images
uploaded = files.upload()

# Create a directory to store uploaded images
os.makedirs("uploaded_images", exist_ok=True)

# Save uploaded images to the directory
for filename in uploaded.keys():
    with open(os.path.join("uploaded_images", filename), 'wb') as f:
        f.write(uploaded[filename])

# Step 4: Load the trained model and run inference
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
import matplotlib.pyplot as plt
import cv2


# Run the model on uploaded images
for filename in uploaded.keys():
    img_path = os.path.join("uploaded_images", filename)
    img = cv2.imread(img_path)
    outputs = predictor(img)

    v = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    plt.figure(figsize=(10, 10))
    plt.imshow(out.get_image()[:, :, ::-1])
    plt.axis('off')
    plt.title(filename)
    plt.show()